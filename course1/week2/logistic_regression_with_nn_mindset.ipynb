{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "logistic_regression_with_nn_mindset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1z2ZP3xqeB_jjt5_ijlyVJSIRS6-cZuq2",
      "authorship_tag": "ABX9TyPdp46sXLLjoOJSAMRyCjDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavkantgaur/Coursera_DL_specialization_from_scratch/blob/master/course1/week2/logistic_regression_with_nn_mindset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ5YZ2gY8y49",
        "colab_type": "code",
        "outputId": "159b656f-28f8-41b7-fcac-a84421d8350a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qoA9qFTtRWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algenbra\n",
        "import matplotlib.pyplot as plt # plotting\n",
        "import h5py # data loading for hdf5 dataset\n",
        "from PIL import Image # for loading your images for processing\n",
        "from scipy import ndimage \n",
        "#from lr_utils import load_dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQhWjN4N82NH",
        "colab_type": "code",
        "outputId": "964d2eb0-6139-49b7-a727-802eefe802ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0qdb183zyTs",
        "colab_type": "text"
      },
      "source": [
        "## Problem statement\n",
        "a training set of m_train images, labeled as cat (y =1) or not-cat (y = 0).\n",
        "a test set of m_test_images\n",
        "each image is of shape (num_px, num_px, 3), RGB channels \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lM4n7arh2ubw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# implementing utility function for loading cat vs non-cat datasets\n",
        "def load_dataset():\n",
        "  train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
        "  test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
        "  train_set_x = np.array(train_dataset[\"train_set_x\"][:])\n",
        "  train_set_y = np.array(train_dataset[\"train_set_y\"][:])\n",
        "  test_set_x  = np.array(test_dataset[\"test_set_x\"][:])\n",
        "  test_set_y = np.array(test_dataset[\"test_set_y\"][:])\n",
        "  classes = np.array(train_dataset[\"list_classes\"][:])\n",
        "\n",
        "  # lets reshape the arrays\n",
        "  train_set_y = train_set_y.reshape((1, train_set_y.shape[0]))\n",
        "  test_set_y = test_set_y.reshape((1, test_set_y.shape[0]))\n",
        "\n",
        "  return train_set_x, train_set_y, test_set_x, test_set_y, classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ArWwvFhs0ZvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load training dataset\n",
        "x_train_images, y_train_images, x_test_images, y_test_images, classes = load_dataset()\n",
        "# x_train_images: (m, nx, ny, nc)\n",
        "# y_train_images: (1, m)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrBAKBJWBQZ3",
        "colab_type": "code",
        "outputId": "39d52db4-9c14-425b-a43e-68067fb06bb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        }
      },
      "source": [
        "# lets inspect the dataset\n",
        "image_id = 25\n",
        "plt.imshow(x_train_images[image_id])\n",
        "print(\"y = \", y_train_images[0][image_id], \"Its a \" + classes[y_train_images[0][image_id]].decode(\"utf-8\") + \" picture!!\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y =  1 Its a cat picture!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCKChIqAEasY",
        "colab_type": "code",
        "outputId": "347451ff-1c6f-4fdc-9e23-23cb9f0ebddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# lets inspect the shapes of the dataset arrays\n",
        "print(\"Training set shape: \", x_train_images.shape) #  m, nx, ny, nc\n",
        "print(\"Training set labels shape: \", y_train_images.shape) # 1, m\n",
        "print(\"Test set shape: \", x_test_images.shape)\n",
        "print(\"Test set labels shape: \", y_test_images.shape)\n",
        "print(\"Each image is of shape: \", x_train_images[0].shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set shape:  (209, 64, 64, 3)\n",
            "Training set labels shape:  (1, 209)\n",
            "Test set shape:  (50, 64, 64, 3)\n",
            "Test set labels shape:  (1, 50)\n",
            "Each image is of shape:  (64, 64, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9JaxwWHGU9M",
        "colab_type": "code",
        "outputId": "e28e0b8d-a3b5-4d0c-b382-d14452b15100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Lets flatten the train and test image dataset for training\n",
        "x_train_images_flattened = x_train_images.reshape((x_train_images.shape[0], x_train_images.shape[1] * \n",
        "                                                   x_train_images.shape[2] * \n",
        "                                                   x_train_images.shape[3], 1)) \n",
        "x_train_images_flattened = np.squeeze(x_train_images_flattened)\n",
        "x_train_images_flattened = x_train_images_flattened.T\n",
        "x_test_images_flattened = x_test_images.reshape((x_test_images.shape[0], x_train_images.shape[1] * \n",
        "                                                 x_test_images.shape[2] * \n",
        "                                                 x_test_images.shape[3], 1))\n",
        "\n",
        "x_test_images_flattened = np.squeeze(x_test_images_flattened)\n",
        "x_test_images_flattened = x_test_images_flattened.T\n",
        "\n",
        "# lets print\n",
        "print(\"Flattened version of train images: \", x_train_images_flattened.shape)\n",
        "print(\"Label set for training dataset: \", y_train_images.shape)\n",
        "print(\"Flattened version of test images: \", x_test_images_flattened.shape)\n",
        "print(\"Label set for test dataset: \", y_test_images.shape)\n",
        "\n",
        "\n",
        "print(\"Sanity check after reshaping: \", x_train_images_flattened[0:5, 0])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Flattened version of train images:  (12288, 209)\n",
            "Label set for training dataset:  (1, 209)\n",
            "Flattened version of test images:  (12288, 50)\n",
            "Label set for test dataset:  (1, 50)\n",
            "Sanity check after reshaping:  [17 31 56 22 33]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Gmt4dlG44u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalization\n",
        "x_train_images = x_train_images_flattened / 255.0\n",
        "x_test_images = x_test_images_flattened / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUqz0K1g5LKs",
        "colab_type": "text"
      },
      "source": [
        "## Time to design architecture for Cat vs non-Cat problem\n",
        "A logistic unit(forward calculations):\n",
        "\\begin{equation*}\n",
        "z^{(i)} = w^{T}x^{(i)} + b\n",
        "\\end{equation*}\n",
        "\\begin{equation*}\n",
        "y' = a^{(i)} = sigmoid(z^{(i)})\n",
        "\\end{equation*}\n",
        "\\begin{equation*}\n",
        "L(y'^{(i)}, y^{(i)}) = - y ^{(i)} log(y'^{i}) - (1 - y^{(i)})log(1 - y'^{(i)})\n",
        "\\end{equation*}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQ5-uORb7ueP",
        "colab_type": "text"
      },
      "source": [
        "The main steps for building a Neural Network are:\n",
        "\n",
        "    Define the model structure (such as number of input features)\n",
        "    Initialize the model's parameters\n",
        "    Loop:\n",
        "        Calculate current loss (forward propagation)\n",
        "        Calculate current gradient (backward propagation)\n",
        "        Update parameters (gradient descent)\n",
        "\n",
        "You often build 1-3 separately and integrate them into one function we call model()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdIxYStpC59e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "  sigm = 1 / (1 + np.exp(-1.0 * z))\n",
        "  return sigm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxlol_oV8MWh",
        "colab_type": "code",
        "outputId": "d8589dfe-082e-4696-e3a4-7d9074d7b662",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# create model class\n",
        "class CatvsNoncatClassifier(object):\n",
        "  def __init__(self, input_size, num_hidden_units = 1):\n",
        "    self.n_hidden_units = num_hidden_units\n",
        "    self.w = np.zeros((self.n_hidden_units, input_size), dtype = 'float32')\n",
        "    self.b = np.zeros((self.n_hidden_units, 1), dtype = 'float32')\n",
        "    self.build_model()\n",
        "  \n",
        "  def build_model(self): # not required here since foward_prop and back_prop will \n",
        "    None                 # do that\n",
        "    \n",
        "   \n",
        "  def initialize_parameters(self, x_shape):\n",
        "    # init w and b\n",
        "    self.w = np.zeros((self.n_hidden_units, x_shape), dtype = 'float32')\n",
        "    self.b = np.zeros((self.n_hidden_units, 1), dtype = 'float32')\n",
        "  \n",
        "  def forward_propogation(self, x):\n",
        "    z = np.dot(self.w, x) + self.b\n",
        "    y_predicted = sigmoid(z)\n",
        "    return y_predicted\n",
        "\n",
        "  def compute_cost(self, y_predicted, y_ground):\n",
        "    \n",
        "    L = -1.0 * np.mean(np.dot(y_ground, np.log(y_predicted).T) + np.dot((1 - y_ground), np.log(1 - y_predicted).T)) # cross entropy loss\n",
        "    #L = np.mean(np.square(np.abs(y_ground - y_predicted))) # mean square loss\n",
        "    return L    \n",
        "\n",
        "  def backward_propogation(self, x, y_predicted, y_ground):\n",
        "    dw = (y_predicted - y_ground) * x.T\n",
        "    db = (y_predicted - y_ground) \n",
        "    #print(\"shape of y_ground: \", y_ground.shape)\n",
        "    #print(\"shape of y_predicted: \", y_predicted.shape)\n",
        "    #print(\"value of dw: \", dw)\n",
        "    #print(\"value of db: \", db)\n",
        "    return dw, db # both are vectors\n",
        "\n",
        "  def update_parameters(self, dw, db, learning_rate):     \n",
        "    self.w = self.w - learning_rate * dw\n",
        "    self.b = self.b - learning_rate * db\n",
        "    \n",
        "    \n",
        "  def train_model(self, x, y_ground, learning_rate = 0.001, n_training_epochs = 10):\n",
        "    self.initialize_parameters(x.shape[0])\n",
        "    \n",
        "    for i in range(n_training_epochs): # no concept of mini-batch yet.\n",
        "      predictions = [] # for collecting predictions across an epoch\n",
        "      ground_truths = []\n",
        "      for j in range(x.shape[1]): # for each training example\n",
        "        x_sample = x[:, j]\n",
        "        x_sample = x_sample.reshape(x_sample.shape[0], 1)\n",
        "        y_sample  = y_ground[:, j]\n",
        "        y_sample = y_sample.reshape(1, y_sample.shape[0])\n",
        "\n",
        "        y_predicted = self.forward_propogation(x_sample) \n",
        " \n",
        "        dw, db = self.backward_propogation(x_sample, y_predicted, y_sample)\n",
        "        self.update_parameters(dw, db, learning_rate)\n",
        "        predictions.append(y_predicted)\n",
        "        ground_truths.append(y_sample)\n",
        "\n",
        "      predictions_array = np.asarray(predictions).reshape(1, len(predictions))\n",
        "      ground_truths_array = np.asarray(ground_truths).reshape(1, len(ground_truths))\n",
        "      print(\"Loss value at epoch: \", i, \" is: \", self.compute_cost(predictions_array, \n",
        "                                                              ground_truths_array))        \n",
        "   \n",
        "  def evaluate_model(self, x_test, y_test):\n",
        "     predictions = []\n",
        "     grounds = []\n",
        "     for i in range(x_test.shape[1]):\n",
        "       y_predicted = self.forward_propogation(x_test[:, i])\n",
        "       predictions.append(y_predicted)\n",
        "       grounds.append(y_test[:, i])\n",
        "     print(\"Accuarcy of the trained model: \", 100 - np.mean(np.abs(np.asarray(predictions).reshape(len(predictions), 1) \n",
        "                                                                  - np.asarray(grounds).reshape(len(grounds), 1)))\n",
        "                                                                  * 100, \"%\")\n",
        "           \n",
        "# main function\n",
        "if __name__ == '__main__':\n",
        "  # data(train and test) has already being loaded and preprocessed\n",
        "  classifier = CatvsNoncatClassifier(num_hidden_units=1, input_size = x_train_images.shape[0])\n",
        "  classifier.train_model(x_train_images, y_train_images, learning_rate = 0.001,\n",
        "                         n_training_epochs = 200)\n",
        "  classifier.evaluate_model(x_test_images, y_test_images)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss value at epoch:  0  is:  172.67465539419584\n",
            "Loss value at epoch:  1  is:  153.07508678339286\n",
            "Loss value at epoch:  2  is:  139.87019120893837\n",
            "Loss value at epoch:  3  is:  129.5436223288432\n",
            "Loss value at epoch:  4  is:  120.89926346821768\n",
            "Loss value at epoch:  5  is:  113.33168851051317\n",
            "Loss value at epoch:  6  is:  106.56085946765333\n",
            "Loss value at epoch:  7  is:  100.47693690754473\n",
            "Loss value at epoch:  8  is:  95.01303113840586\n",
            "Loss value at epoch:  9  is:  90.10431842037471\n",
            "Loss value at epoch:  10  is:  85.6855622233918\n",
            "Loss value at epoch:  11  is:  81.69464724477132\n",
            "Loss value at epoch:  12  is:  78.07500344002648\n",
            "Loss value at epoch:  13  is:  74.77669608260902\n",
            "Loss value at epoch:  14  is:  71.75664815869027\n",
            "Loss value at epoch:  15  is:  68.97830963375307\n",
            "Loss value at epoch:  16  is:  66.41100337166134\n",
            "Loss value at epoch:  17  is:  64.029128163288\n",
            "Loss value at epoch:  18  is:  61.81134503214609\n",
            "Loss value at epoch:  19  is:  59.73982133101082\n",
            "Loss value at epoch:  20  is:  57.79956844962674\n",
            "Loss value at epoch:  21  is:  55.97788444712134\n",
            "Loss value at epoch:  22  is:  54.26389904689342\n",
            "Loss value at epoch:  23  is:  52.64821119591832\n",
            "Loss value at epoch:  24  is:  51.122605999912835\n",
            "Loss value at epoch:  25  is:  49.679836758223786\n",
            "Loss value at epoch:  26  is:  48.31345826913589\n",
            "Loss value at epoch:  27  is:  47.017699082394344\n",
            "Loss value at epoch:  28  is:  45.78736250055674\n",
            "Loss value at epoch:  29  is:  44.617748436977244\n",
            "Loss value at epoch:  30  is:  43.50459036864416\n",
            "Loss value at epoch:  31  is:  42.44400336499133\n",
            "Loss value at epoch:  32  is:  41.43244046655161\n",
            "Loss value at epoch:  33  is:  40.4666555726842\n",
            "Loss value at epoch:  34  is:  39.54367156768978\n",
            "Loss value at epoch:  35  is:  38.66075276756803\n",
            "Loss value at epoch:  36  is:  37.81538098654166\n",
            "Loss value at epoch:  37  is:  37.005234660535734\n",
            "Loss value at epoch:  38  is:  36.2281705599459\n",
            "Loss value at epoch:  39  is:  35.48220769647341\n",
            "Loss value at epoch:  40  is:  34.76551308877995\n",
            "Loss value at epoch:  41  is:  34.076389103782844\n",
            "Loss value at epoch:  42  is:  33.413262136293284\n",
            "Loss value at epoch:  43  is:  32.774672429921566\n",
            "Loss value at epoch:  44  is:  32.15926487690457\n",
            "Loss value at epoch:  45  is:  31.565780663945773\n",
            "Loss value at epoch:  46  is:  30.99304965562888\n",
            "Loss value at epoch:  47  is:  30.43998342694669\n",
            "Loss value at epoch:  48  is:  29.90556887253814\n",
            "Loss value at epoch:  49  is:  29.388862332946097\n",
            "Loss value at epoch:  50  is:  28.888984188180743\n",
            "Loss value at epoch:  51  is:  28.405113876633468\n",
            "Loss value at epoch:  52  is:  27.936485303406187\n",
            "Loss value at epoch:  53  is:  27.482382606795895\n",
            "Loss value at epoch:  54  is:  27.042136255327726\n",
            "Loss value at epoch:  55  is:  26.615119450617073\n",
            "Loss value at epoch:  56  is:  26.20074481365978\n",
            "Loss value at epoch:  57  is:  25.798461334046976\n",
            "Loss value at epoch:  58  is:  25.407751563187865\n",
            "Loss value at epoch:  59  is:  25.028129033978914\n",
            "Loss value at epoch:  60  is:  24.65913589053912\n",
            "Loss value at epoch:  61  is:  24.300340712678207\n",
            "Loss value at epoch:  62  is:  23.95133652070887\n",
            "Loss value at epoch:  63  is:  23.611738947075132\n",
            "Loss value at epoch:  64  is:  23.281184562065036\n",
            "Loss value at epoch:  65  is:  22.959329341618\n",
            "Loss value at epoch:  66  is:  22.645847265937697\n",
            "Loss value at epoch:  67  is:  22.34042903828701\n",
            "Loss value at epoch:  68  is:  22.042780913980536\n",
            "Loss value at epoch:  69  is:  21.75262363020768\n",
            "Loss value at epoch:  70  is:  21.469691427919383\n",
            "Loss value at epoch:  71  is:  21.193731157596886\n",
            "Loss value at epoch:  72  is:  20.924501461292984\n",
            "Loss value at epoch:  73  is:  20.66177202389531\n",
            "Loss value at epoch:  74  is:  20.405322887105594\n",
            "Loss value at epoch:  75  is:  20.154943820157797\n",
            "Loss value at epoch:  76  is:  19.91043374180809\n",
            "Loss value at epoch:  77  is:  19.671600188618896\n",
            "Loss value at epoch:  78  is:  19.438258825024533\n",
            "Loss value at epoch:  79  is:  19.21023299110493\n",
            "Loss value at epoch:  80  is:  18.987353284404506\n",
            "Loss value at epoch:  81  is:  18.769457172513793\n",
            "Loss value at epoch:  82  is:  18.556388633481433\n",
            "Loss value at epoch:  83  is:  18.34799782144237\n",
            "Loss value at epoch:  84  is:  18.144140755136576\n",
            "Loss value at epoch:  85  is:  17.944679027250267\n",
            "Loss value at epoch:  86  is:  17.749479532742114\n",
            "Loss value at epoch:  87  is:  17.55841421451973\n",
            "Loss value at epoch:  88  is:  17.371359825011293\n",
            "Loss value at epoch:  89  is:  17.18819770233368\n",
            "Loss value at epoch:  90  is:  17.008813559895795\n",
            "Loss value at epoch:  91  is:  16.83309728839476\n",
            "Loss value at epoch:  92  is:  16.660942769267354\n",
            "Loss value at epoch:  93  is:  16.492247698749146\n",
            "Loss value at epoch:  94  is:  16.326913421773305\n",
            "Loss value at epoch:  95  is:  16.16484477501062\n",
            "Loss value at epoch:  96  is:  16.005949938412982\n",
            "Loss value at epoch:  97  is:  15.85014029467697\n",
            "Loss value at epoch:  98  is:  15.697330296092167\n",
            "Loss value at epoch:  99  is:  15.547437338281773\n",
            "Loss value at epoch:  100  is:  15.400381640381976\n",
            "Loss value at epoch:  101  is:  15.256086131241512\n",
            "Loss value at epoch:  102  is:  15.114476341254933\n",
            "Loss value at epoch:  103  is:  14.975480299471917\n",
            "Loss value at epoch:  104  is:  14.839028435652263\n",
            "Loss value at epoch:  105  is:  14.705053486960384\n",
            "Loss value at epoch:  106  is:  14.573490409015948\n",
            "Loss value at epoch:  107  is:  14.444276291038285\n",
            "Loss value at epoch:  108  is:  14.317350274841692\n",
            "Loss value at epoch:  109  is:  14.192653477456181\n",
            "Loss value at epoch:  110  is:  14.070128917165263\n",
            "Loss value at epoch:  111  is:  13.949721442767224\n",
            "Loss value at epoch:  112  is:  13.831377665880657\n",
            "Loss value at epoch:  113  is:  13.715045896127677\n",
            "Loss value at epoch:  114  is:  13.60067607904056\n",
            "Loss value at epoch:  115  is:  13.488219736548238\n",
            "Loss value at epoch:  116  is:  13.3776299099092\n",
            "Loss value at epoch:  117  is:  13.268861104966756\n",
            "Loss value at epoch:  118  is:  13.161869239611029\n",
            "Loss value at epoch:  119  is:  13.05661159333974\n",
            "Loss value at epoch:  120  is:  12.953046758817226\n",
            "Loss value at epoch:  121  is:  12.851134595337466\n",
            "Loss value at epoch:  122  is:  12.750836184102955\n",
            "Loss value at epoch:  123  is:  12.652113785236867\n",
            "Loss value at epoch:  124  is:  12.554930796450854\n",
            "Loss value at epoch:  125  is:  12.459251713295458\n",
            "Loss value at epoch:  126  is:  12.365042090924597\n",
            "Loss value at epoch:  127  is:  12.272268507309015\n",
            "Loss value at epoch:  128  is:  12.180898527837886\n",
            "Loss value at epoch:  129  is:  12.09090067125019\n",
            "Loss value at epoch:  130  is:  12.002244376841457\n",
            "Loss value at epoch:  131  is:  11.914899972893538\n",
            "Loss value at epoch:  132  is:  11.828838646278207\n",
            "Loss value at epoch:  133  is:  11.744032413187458\n",
            "Loss value at epoch:  134  is:  11.660454090945944\n",
            "Loss value at epoch:  135  is:  11.578077270862785\n",
            "Loss value at epoch:  136  is:  11.49687629208227\n",
            "Loss value at epoch:  137  is:  11.41682621639443\n",
            "Loss value at epoch:  138  is:  11.337902803968621\n",
            "Loss value at epoch:  139  is:  11.260082489974444\n",
            "Loss value at epoch:  140  is:  11.183342362056191\n",
            "Loss value at epoch:  141  is:  11.10766013862817\n",
            "Loss value at epoch:  142  is:  11.033014147959843\n",
            "Loss value at epoch:  143  is:  10.95938330802087\n",
            "Loss value at epoch:  144  is:  10.886747107057289\n",
            "Loss value at epoch:  145  is:  10.81508558487143\n",
            "Loss value at epoch:  146  is:  10.74437931477909\n",
            "Loss value at epoch:  147  is:  10.674609386218485\n",
            "Loss value at epoch:  148  is:  10.605757387986763\n",
            "Loss value at epoch:  149  is:  10.53780539208046\n",
            "Loss value at epoch:  150  is:  10.470735938117398\n",
            "Loss value at epoch:  151  is:  10.404532018318426\n",
            "Loss value at epoch:  152  is:  10.339177063027982\n",
            "Loss value at epoch:  153  is:  10.274654926753584\n",
            "Loss value at epoch:  154  is:  10.210949874704763\n",
            "Loss value at epoch:  155  is:  10.148046569813044\n",
            "Loss value at epoch:  156  is:  10.085930060214874\n",
            "Loss value at epoch:  157  is:  10.02458576718055\n",
            "Loss value at epoch:  158  is:  9.963999473472288\n",
            "Loss value at epoch:  159  is:  9.904157312115665\n",
            "Loss value at epoch:  160  is:  9.845045755569068\n",
            "Loss value at epoch:  161  is:  9.786651605276266\n",
            "Loss value at epoch:  162  is:  9.728961981587942\n",
            "Loss value at epoch:  163  is:  9.671964314038451\n",
            "Loss value at epoch:  164  is:  9.61564633196464\n",
            "Loss value at epoch:  165  is:  9.559996055453954\n",
            "Loss value at epoch:  166  is:  9.505001786609618\n",
            "Loss value at epoch:  167  is:  9.450652101121168\n",
            "Loss value at epoch:  168  is:  9.39693584012893\n",
            "Loss value at epoch:  169  is:  9.343842102371486\n",
            "Loss value at epoch:  170  is:  9.291360236605712\n",
            "Loss value at epoch:  171  is:  9.239479834289149\n",
            "Loss value at epoch:  172  is:  9.188190722515117\n",
            "Loss value at epoch:  173  is:  9.13748295719095\n",
            "Loss value at epoch:  174  is:  9.087346816450571\n",
            "Loss value at epoch:  175  is:  9.037772794292515\n",
            "Loss value at epoch:  176  is:  8.988751594435152\n",
            "Loss value at epoch:  177  is:  8.940274124380945\n",
            "Loss value at epoch:  178  is:  8.892331489682121\n",
            "Loss value at epoch:  179  is:  8.844914988400127\n",
            "Loss value at epoch:  180  is:  8.798016105751827\n",
            "Loss value at epoch:  181  is:  8.751626508935427\n",
            "Loss value at epoch:  182  is:  8.705738042129536\n",
            "Loss value at epoch:  183  is:  8.660342721658921\n",
            "Loss value at epoch:  184  is:  8.61543273132079\n",
            "Loss value at epoch:  185  is:  8.571000417865719\n",
            "Loss value at epoch:  186  is:  8.527038286627455\n",
            "Loss value at epoch:  187  is:  8.483538997296142\n",
            "Loss value at epoch:  188  is:  8.440495359829708\n",
            "Loss value at epoch:  189  is:  8.397900330498278\n",
            "Loss value at epoch:  190  is:  8.355747008056738\n",
            "Loss value at epoch:  191  is:  8.31402863004083\n",
            "Loss value at epoch:  192  is:  8.272738569182106\n",
            "Loss value at epoch:  193  is:  8.231870329937552\n",
            "Loss value at epoch:  194  is:  8.19141754512956\n",
            "Loss value at epoch:  195  is:  8.15137397269232\n",
            "Loss value at epoch:  196  is:  8.111733492520717\n",
            "Loss value at epoch:  197  is:  8.072490103418021\n",
            "Loss value at epoch:  198  is:  8.033637920138794\n",
            "Loss value at epoch:  199  is:  7.995171170523568\n",
            "Accuarcy of the trained model:  67.96844495061393 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}