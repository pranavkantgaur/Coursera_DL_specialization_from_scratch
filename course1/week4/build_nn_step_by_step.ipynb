{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "build_nn_step_by_step.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM3Y7Bx8zai1ZR3tclOLQia",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranavkantgaur/Coursera_DL_specialization_from_scratch/blob/master/course1/week4/build_nn_step_by_step.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k89MutsNmCu4",
        "colab_type": "text"
      },
      "source": [
        "## Objectives\n",
        "To be able to build and train NNs for various depth and width. This assignment is not tied to any application, therefore it will be evaluated using test cases. The functions developed in this notebook will be used in the next assignment. Target is to build:\n",
        "\n",
        "\n",
        "*   A 2-layer NN\n",
        "*   A L-layer NN\n",
        "\n",
        "Effectively, I will be able to build and train a L-layer fully connected NN, entirely using Numpy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOYV-4ivlzfb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TwoLayerNN(object):\n",
        "  def __init__(self):\n",
        "    # hyperparameters\n",
        "    self.n_hidden_units = n_hidden_units # len(self.n_hidden_units = number of layers)\n",
        "    self.n_epochs = 0\n",
        "    self.lr = 0\n",
        "    # parameters\n",
        "    self.w1 = 0\n",
        "    self.b1 = 0\n",
        "    self.w2 = 0\n",
        "    self.b2 = 0\n",
        "    self.w3 = 0\n",
        "    self.b3 = 0\n",
        "\n",
        "  def forward(self, X):\n",
        "    # layer 1\n",
        "    z1 = np.dot(self.w1, X) + self.b1\n",
        "    a1 = np.tanh(z1)\n",
        "    \n",
        "    # layer 2\n",
        "    z2 = np.dot(self.w2, a1) + self.b2\n",
        "    a2 = np.tanh(z2)\n",
        "    \n",
        "    # layer 3 (output)\n",
        "    z3 = np.dot(self.w3, a2) + self.b3\n",
        "    a3 = sigmoid(z3)\n",
        "\n",
        "    return a1, a2, a3\n",
        "\n",
        "  def initialize_parameters(self):\n",
        "    self.w1 = np.random.randn(n_hidden_units[0], input_size) * 0.01\n",
        "    self.b1 = np.zeros(n_hidden_units[0], 1)\n",
        "    self.w2 = np.random.randn(n_hidden_units[1], num_hidden_units[0]) * 0.01\n",
        "    self.b2 = np.zeros(n_hidden_units[1], 1)\n",
        "    self.w3 = np.random.randn(n_hidden_units[2], num_hidden_units[1]) * 0.01\n",
        "    self.b3 = np.zeros(n_hidden_units[2], 1)\n",
        "\n",
        "\n",
        "  def backward(self):\n",
        "    '''\n",
        "    Notice that the only difference across layers lies in computation of dZ, \n",
        "    rest all can be parameterized on layer ID.\n",
        "    '''\n",
        "    dZ3 = A3 - Y # output layer\n",
        "    dw3 = np.dot(dZ3, A2.T) / m\n",
        "    db3 = np.mean(dZ3)\n",
        "    \n",
        "    dZ2 = np.dot(self.w2.T, dZ3) * (1 - np.power(A2, 2))\n",
        "    dw2 = np.dot(dZ2, A1.T) / m\n",
        "    db2 = np.mean(dZ2)\n",
        "\n",
        "    dZ1 = np.dot(self.w1.T, dZ2) * (1 - np.power(A1, 1))\n",
        "    dw1 = np.dot(dZ1, X.T) / m\n",
        "    db1 = np.mean(dZ1)\n",
        "\n",
        "    return dw1, db1, dw2, db2, dw3, db3\n",
        "\n",
        "  def update_parameters(self):\n",
        "    None\n",
        "  def compute_cost(self):\n",
        "    None\n",
        "  def train(self):\n",
        "    None\n",
        "  def evaluate(self):\n",
        "    None              \n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsLDWSlcowUr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twoNN = TwoLayerNN()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JSuAEWMo04O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twoNN.train()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKsvpg67o2we",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "twoNN.evaluate()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}